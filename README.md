<a name="readme-top"></a>

<div align="center">
  <img src="./assets/icon_light_bg.svg" alt="Logo" width="200">
  <h1 align="center">constellaXion CLI: Automated LLM Deployments for your private cloud</h1>
</div>

<div align="center">
  <a href="https://constellaxion.ai"><img src="https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&color=A0C7FE&logo=homepage&logoColor=white" alt="Project Page"></a>
  <a href="https://constellaxion.github.io"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=A0C7FE&style=for-the-badge" alt="Check out the documentation"></a>
  <hr>
</div>



The fastest way to **Train, Deploy and Serve** Open Source Language Models to your Cloud environment

## âš¡ï¸ Features
Configure and access the most popular open source LLMs with a few simple commands

- ğŸš„ Fine-tune your own models using your own data and cloud resources

- ğŸš€ Deploy models to your private cloud environment

- ğŸ¤– Serve your models with ease

- ğŸ’¬ Prompt your models with ease


## Installation

Install the package:

```sh
pip install constellaxion
```


## Usage
1. Init your model:

    ```sh
    constellaXion init
    ```

2. View Training and Serving configurations:

    ```sh
    constallaXion model view
    ```

3. Run training job:

    ```sh
    constallaXion model train
    ```

4. Serve model:

    ```sh
    constallaXion model serve
    ```

5. Prompt model:

    ```sh
    constallaXion model prompt
    ```
